---
title: "cloud"
author: "gordon"
date: "2018年10月4日"
output: html_document
---
##先用google爬有關"你的名字"的PTT文章
```{r }
rm(list = ls(all=TRUE))
library(rvest)
web1='https://www.google.com.tw/search?q='

topic =curl_escape("2017秋番") # google 主題
long=1 # google 頁數

webname=topic
web2='+ptt+site:www.ptt.cc&rlz=1C1GCEA_enTW762TW762&ei=njSjW5PDMIj08gWx8Je4DA&start='
webnum=''
webfinal='&sa=N&biw=1280&bih=653'
website=c()
long=long-1
for(i in 0:long){
  webnum=as.character(i*10)
  web=paste(web1,webname,web2,webnum,webfinal,sep="")
  doc1 <- read_html(web)
  block=html_nodes(doc1,".r")
  text1=html_text(block)
  for (j in 1:10){
    website[j+i*10]=xml_attrs(xml_child(block[[j]], 1))[["href"]]#獲取網址
  }
  
}
print("down")
a=website  #診裡網址
a=strsplit(a,'&')

for (i in 1:(10*long+10)){
  a[[i]]=a[[i]][1]
  a[[i]]=strsplit(a[[i]],'=')
}
for (i in 1:(10*long+10)){
  a[[i]]=a[[i]][[1]][2]
}
website=a
#a=0
head(website)#整理完畢
#進入PTT


```

```{r}
txtlist=list()
for (i in 1:((long*10)+10)){
  doc1=read_html(website[[i]])
  
  txt=html_text(doc1)
  #txt=strsplit(txt,'NTUcourse標題')#整理文章10篇
  txtlist[i] <- txt
  
}

```




##將收集到的資料繪製成文字圖

```{r }


setwd('D:/R/R data/TextMining')
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)


docs <- Corpus(VectorSource(txtlist))

toSpace <- content_transformer(function(x, pattern) {
  return (gsub(pattern, " ", x))
}
)


docs <- tm_map(docs, toSpace, "※")


docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")

pop_list=c("作品",'視覺',"什麼","可以","這部","因為","所以","不過","其實","應該","如果","覺得","不是","沒有","這樣","還是","一樣","不會","只是","可能"
,"時候","可能","知道","時候","最後","就是","真的","動畫","影片","制作","監督","原作","構成","系列")# 用迴圈過濾廢字
for (i in 1:length(pop_list)){
  docs <- tm_map(docs, toSpace, pop_list[i])
}
  #導演的名字,片名
#docs <- tm_map(docs,removeWords,stopwordsCN())#移除常用廢字
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)

mixseg = worker()
new_user_word(mixseg, "新海誠","你的名字")
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))


```

```{r}
frevar1=as.character(freqFrame$Var1)
frevar=nchar(frevar1)>1
freqFrame=freqFrame[frevar,]
freqFrame=freqFrame[rev(order(freqFrame$Freq)),]
freqFrame
#library(ggplot2)
#ggplot(subset(freqFrame,Freq>50),aes(x=reorder(Var1,-Freq),y=Freq))+geom_bar(stat="identity")#依照詞頻率繪製柱狀圖

```
```{r}
wordcloud(freqFrame$Var1,freqFrame$Freq,
          scale=c(4,0.1),min.freq=4,max.words=140,
          random.order=TRUE, random.color=FALSE, 
          rot.per=.1, colors=brewer.pal(8, "Dark2"),
          ordered.colors=FALSE,use.r.layout=FALSE,
          fixed.asp=TRUE)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
